# ğŸ“œ telex-nlp
In this project, I attempt to build a small language model, trained on all the articles of the Hungarian news portal [telex.hu](https://telex.hu/), using a character-based tokenizer.


## ğŸ”§ Set up environment
The python environment is managed with [pipenv](https://pipenv.pypa.io/en/latest/install). You can set up your environment with the following steps:

- Run `pipenv lock`to generate the `Pipfile.lock` which lists the version of your python packages.
- Run `pipenv install --dev` to actually create a virtual environment and install the python packages. The flag `--dev` allows to install the development packages (for linting, ...).
- Run `pipenv shell` to activate the virtual environment

## ğŸš€ Run the DVC pipeline

The ML pipeline is managed with [DVC](https://dvc.org/), here are a few tips on how to use it:

- Run the complete pipeline: `dvc repro`
- Run a specific step of the pipeline with all its dependencies: `dvc repro <step_name>`

DVC Sages:
- scrape        : using the telex api downloads and saves all articles published since 2020 october
- prerpocess    : removes html, tags, and collects all article contents in a single json
- train         : Dataloader and LM model is initialized, training on characterwise in semi-supervised fashion
- evaluate      : calculates corpus perplexity on a test set, generates random text from input context

## ğŸ—ï¸ Structure
<pre>
.
â”œâ”€â”€ Pipfile                 <- requirements for running the project
â”œâ”€â”€ Pipfile.lock            <- versions of the required packages
â”œâ”€â”€ README.md
â”œâ”€â”€ dvc.lock                <- automatically records the states of the DVC pipeline
â”œâ”€â”€ dvc.yaml                <- lists the stages for the DVC pipeline
â”œâ”€â”€ pyproject.toml          <- contains the build system requirements of the projects
â”œâ”€â”€ notebooks
â”œâ”€â”€ params.py               <- contains the parameters of the project
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ preprocessed
â”‚Â Â  â””â”€â”€ raw
â””â”€â”€ telex                   <- source code of the project
    â”œâ”€â”€ models              <- ml model definitions
    â”‚Â Â  â”œâ”€â”€ base_model.py
    â”‚Â Â  â”œâ”€â”€ bigram.py
    â”‚Â Â  â””â”€â”€ transformer.py
    â”œâ”€â”€ pipeline            <- scripts for each stage in the DVC pipeline
    â”‚Â Â  â”œâ”€â”€ evaluate
    â”‚Â Â  â”œâ”€â”€ preprocess
    â”‚Â Â  â”œâ”€â”€ scrape          <- scraping articles from telex
    â”‚Â Â  â””â”€â”€ train           <- model training scripts
    â””â”€â”€ utils               <- helper scripts
        â”œâ”€â”€ dataset.py      <- defines pytorch Dataset object from raw articles
        â””â”€â”€ io.py           <- input/output related functions

